{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84130b9e-e6e4-4851-b3ce-b337edf9365f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## BART-CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "080badfa-049d-4c38-bf09-b7fc3df51005",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d457ad9c-121c-419b-846d-54b8a03b4941",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT = \"\"\"\n",
    "Provide a 80 word-summary of the below debate.\n",
    "A bar of soap is better than a bottle of shower gel. Shower gel is more hygienic, especially for a shared shower After one person used a bar of soap there might be hair sticking to it. Shower gels generate a lot more plastic packaging which isn’t always responsibly recycled Shower gel has a lot more bulk and water weight so is inefficient to transport/distribute It is difficult to wash your hair with a bar of soap. Short hair can be just as easily be washed with a soap by just rubbing it over your hair. Soap stings your eyes A lot of soap does not sting in the eyes. Shower gel can sting in your eyes too. Soap is old-fashioned Soap is more convenient in use (no bottle to unscrew/open A bar of soap lasts longer. A bar of soap uses less packaging than shower gel Given the immense damage plastic does to the environment, this is a vital factor to consider. Soap is cheaper than shower gel It is easier to drop soap in the shower.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0ccdbe5-b6fe-43d3-94ca-dac4ee1ba375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'summary_text': 'A bar of soap is better than a bottle of shower gel. Shower gel is more hygienic, especially for a shared shower. A lot of soap does not sting in the eyes. Soap is old-fashioned. It is easier to drop soap in the shower. Sh shower gels generate a lot more plastic packaging which isn’t always responsibly recycled. It can sting your eyes too.'}]\n"
     ]
    }
   ],
   "source": [
    "print(summarizer(INPUT, max_length=100, min_length=80, do_sample=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef158a97-7949-4ddf-8723-28069d69e2c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'summary_text': 'A bar of soap is better than a bottle of shower gel. Shower gels generate a lot more plastic packaging which isn’t always responsibly recycled. Soap is more convenient in use (no bottle to unscrew/open) Soap lasts longer. It is easier to drop soap in the shower. A lot of soap does not sting in the eyes. Sh shower gel can sting in your eyes too.'}]\n"
     ]
    }
   ],
   "source": [
    "# do_sample=false provides better summary - the model selects the word with the highest probability at each step.\n",
    "print(summarizer(INPUT, max_length=100, min_length=80, do_sample=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0795fa97-fb5e-47fa-95eb-71f1a7be89bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'summary_text': 'A bar of soap is better than a bottle of shower gel. Shower gels generate a lot more plastic packaging which isn’t always responsibly recycled. Soap is more convenient in use (no bottle to unscrew/open) Soap lasts longer. It is easier to drop soap in the shower. A lot of soap does not sting in the eyes. Sh shower gel can sting in your eyes too.'}]\n"
     ]
    }
   ],
   "source": [
    "# default do_sample value is false\n",
    "print(summarizer(INPUT, max_length=100, min_length=80))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7d5a3e36-cddd-41a3-b9cd-7037ee8508be",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = summarizer(INPUT, max_length=100, min_length=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ef32ce1c-e15a-4be2-8c4b-d6f9f5dc51e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A bar of soap is better than a bottle of shower gel. Shower gels generate a lot more plastic packaging which isn’t always responsibly recycled. Soap is more convenient in use (no bottle to unscrew/open) Soap lasts longer. It is easier to drop soap in the shower. A lot of soap does not sting in the eyes. Sh shower gel can sting in your eyes too.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[0]['summary_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd00fdbc-db3c-4c07-83c7-395f0753ae73",
   "metadata": {},
   "outputs": [],
   "source": [
    "## tokenization for bart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "609df336-a4a2-4bb3-896d-bc5a61e67cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1169 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------\n",
      "summary_chunk Provide a summary of the given debate within a limit of 100 words:<s>Are constructed languages useful and do we need more of them? All languages of the world are in fact constructed languages. And we need more of them because of the developing technology. Someday we need to discuss with the robots using some artificial language. We only need to extend the vocabulary of our current languages in order to be able to talk about new technologies. There is no need to build a new language from ground zero. Contemporary Latin is spoken on mailing lists, Latin Wikipedia, and other media. Robots are learning our existing languages, so we don't need to learn their artificial languages. Of course one can say to a robot: Turn your head 180 degrees but I am longing for a more precise language like: Read Robot 1, variable up1 180 degrees and wait. I would not use such a words like: Head but I would use artificial variable names instead because I am afraid of the robot making misunderstanding. Programming languages are useful constructed languages. Even though implementation is unlikely, design a language could be un good creative exercise: to understand different mechanics of language and perspectives Even if an artificial language were to complicated or irregular to learn, it might reveal facts about how we construct language that would otherwise have remained unknown. Even junk DNA like data can perhaps somehow turn to be a source to at least to our inspiration. There are enough languages in the world and many of them are even dying or vanishing. There is no need for any more languages. It makes no sense to abandon a century or millennia old language spoken by large amounts of people and used in large amount of books, in favor of a new language spoken by a minority. A new language doesn't necessarily replace the old; it's imaginable people would speak different languages in different contexts. An already established and popular language that everybody studies or learns is a better tool to bridge communication than a new constructed language. Changes in languages (creation or extinction) are inevitable and happen naturally, so it's possible that the languages that we know today might be completely different in 50 years. Language construction boosts the understanding of linguistic structures by the people practicing it, thus increasing overall literacy. It takes too much time to learn any language. And to learn a constructed language it takes even more time. A far too long time? And all that time is wasted which is used for learning a constructed language. On the contrary, many auxiliary languages are constructed with the simplicity of learning in mind. They lack exceptions in grammar and have more logical structure. Translation apps help those who want to communicate and don't speak the same language easier than a newly constructed language. Google Translate is used by about 200mn people per day. Google translations are often sexist. Voice translators, such as this one, allows to speak into a phone and the app/site translates it instantly. Voice translators and other machine translation apps have their limitations. They cannot interpret pragmatic meaning behind an utterance. Eg. If somebody states 'It's hot in here', they may not be stating a declarative fact but making a request to open a window. Also, some languages like Spanish are more direct than others like English and use more imperatives. What is acceptable to say in Spanish may be impolite in English. Common machine translation apps cannot differentiate this. Translation apps only work as long as there is an internet connection. It would be nice to be part of a team that is creating a new language. Much can be learned and time used for creating a new language will be worthful. There is no use for a language that only a small team can speak. Even such a notable language than SANSKRIT may be put toghether artificially. For the word SANSKRIT in one sense may mean: constructed or put together. Sanskrit - Wikipedia The use of sanskrit is declining. So this constructed language is a failure. What would science for instance mathematics be without their notation languages? All notation languages are some kind of constructed languages? Notation language -\n",
      "----------------------\n",
      "summary_chunk Provide a summary of the given debate within a limit of 100 words:There are enough languages in the world and many of them are even dying or vanishing. There is no need for any more languages. It makes no sense to abandon a century or millennia old language spoken by large amounts of people and used in large amount of books, in favor of a new language. It takes too much time to learn any language. And to learn a constructed language it takes even more time. And all that time is wasted. Wikipedia The constructed language may in some point of view be dangerous for the way that our brains function. Those languages that nowadays exists are all perfect for our brains but any new artificial language may cause some kind of difficulties. The languages have been evolving throughout the whole history of humanity, and are evolving right now. Even the mean speed of language evolution may be measured. Thus, there is no perfect language. All languages are a social construction. Chomsky has argued that we are all born with an innate knowledge of grammar that serves as the basis for all language acquisition. It is impossible to create a new artificial language. There is a great list of those who have tried but without any significant success. Those attemps made after year 1990 shows how impossible it is. A list of constructed languages - Wikipedia It is perfectly possible to create an artificial language. The problem is that most people do not see the need to learn it and use it, even though it would simplify international communication. Klingon is a functional language one can learn on Duolingo as well as the Klingon Language Institute. Many twins develop a common language only they understand and use. This is called cryptophasia. I have seen some books that have got words after words without precise grammar. Why could not they create a new language if they just forget and abandon the grammar when they create a brand new language. But with a loaned grammar they won't get very far in their intentions. That is my opinion only. You seem to have been not well enough informed. See e.g. this. Dothraki was created by a professional linguist and is a functional language with unique grammar. Only a small fraction of today's constructed languages is aimed to have any kind of utilitarian purpose. By far most of the constructed languages are created to satisfy the artistic taste of the author.</s>\n",
      "**************\n",
      "['There are enough languages in the world and many of them are even dying or vanishing. There is no need for any more languages. It makes no sense to abandon a century or millennia old language spoken by large amounts of people and used in large amount of books, in favor of a new language. It takes too much time to learn any language. And to learn a constructed language it takes even more time. And all that time is wasted.', 'There are enough languages in the world and many of them are even dying or vanishing. It makes no sense to abandon a century or millennia old language spoken by large amounts of people and used in large amount of books, in favor of a new language. It takes too much time to learn any language. And to learn a constructed language it takes even more time. And all that time is wasted. It is impossible to create a new artificial language.']\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, BartTokenizer\n",
    "import torch\n",
    "\n",
    "input_text= \"\"\"Are constructed languages useful and do we need more of them? All languages of the world are in fact constructed languages. And we need more of them because of the developing technology. Someday we need to discuss with the robots using some artificial language. We only need to extend the vocabulary of our current languages in order to be able to talk about new technologies. There is no need to build a new language from ground zero. Contemporary Latin is spoken on mailing lists, Latin Wikipedia, and other media. Robots are learning our existing languages, so we don't need to learn their artificial languages. Of course one can say to a robot: Turn your head 180 degrees but I am longing for a more precise language like: Read Robot 1, variable up1 180 degrees and wait. I would not use such a words like: Head but I would use artificial variable names instead because I am afraid of the robot making misunderstanding. Programming languages are useful constructed languages. Even though implementation is unlikely, design a language could be un good creative exercise: to understand different mechanics of language and perspectives Even if an artificial language were to complicated or irregular to learn, it might reveal facts about how we construct language that would otherwise have remained unknown. Even junk DNA like data can perhaps somehow turn to be a source to at least to our inspiration. There are enough languages in the world and many of them are even dying or vanishing. There is no need for any more languages. It makes no sense to abandon a century or millennia old language spoken by large amounts of people and used in large amount of books, in favor of a new language spoken by a minority. A new language doesn't necessarily replace the old; it's imaginable people would speak different languages in different contexts. An already established and popular language that everybody studies or learns is a better tool to bridge communication than a new constructed language. Changes in languages (creation or extinction) are inevitable and happen naturally, so it's possible that the languages that we know today might be completely different in 50 years. Language construction boosts the understanding of linguistic structures by the people practicing it, thus increasing overall literacy. It takes too much time to learn any language. And to learn a constructed language it takes even more time. A far too long time? And all that time is wasted which is used for learning a constructed language. On the contrary, many auxiliary languages are constructed with the simplicity of learning in mind. They lack exceptions in grammar and have more logical structure. Translation apps help those who want to communicate and don't speak the same language easier than a newly constructed language. Google Translate is used by about 200mn people per day. Google translations are often sexist. Voice translators, such as this one, allows to speak into a phone and the app/site translates it instantly. Voice translators and other machine translation apps have their limitations. They cannot interpret pragmatic meaning behind an utterance. Eg. If somebody states 'It's hot in here', they may not be stating a declarative fact but making a request to open a window. Also, some languages like Spanish are more direct than others like English and use more imperatives. What is acceptable to say in Spanish may be impolite in English. Common machine translation apps cannot differentiate this. Translation apps only work as long as there is an internet connection. It would be nice to be part of a team that is creating a new language. Much can be learned and time used for creating a new language will be worthful. There is no use for a language that only a small team can speak. Even such a notable language than SANSKRIT may be put toghether artificially. For the word SANSKRIT in one sense may mean: constructed or put together. Sanskrit - Wikipedia The use of sanskrit is declining. So this constructed language is a failure. What would science for instance mathematics be without their notation languages? All notation languages are some kind of constructed languages? Notation language - Wikipedia The constructed language may in some point of view be dangerous for the way that our brains function. Those languages that nowadays exists are all perfect for our brains but any new artificial language may cause some kind of difficulties. The languages have been evolving throughout the whole history of humanity, and are evolving right now. Even the mean speed of language evolution may be measured. Thus, there is no perfect language. All languages are a social construction. Chomsky has argued that we are all born with an innate knowledge of grammar that serves as the basis for all language acquisition. It is impossible to create a new artificial language. There is a great list of those who have tried but without any significant success. Those attemps made after year 1990 shows how impossible it is. A list of constructed languages - Wikipedia It is perfectly possible to create an artificial language. The problem is that most people do not see the need to learn it and use it, even though it would simplify international communication. Klingon is a functional language one can learn on Duolingo as well as the Klingon Language Institute. Many twins develop a common language only they understand and use. This is called cryptophasia. I have seen some books that have got words after words without precise grammar. Why could not they create a new language if they just forget and abandon the grammar when they create a brand new language. But with a loaned grammar they won't get very far in their intentions. That is my opinion only. You seem to have been not well enough informed. See e.g. this. Dothraki was created by a professional linguist and is a functional language with unique grammar. Only a small fraction of today's constructed languages is aimed to have any kind of utilitarian purpose. By far most of the constructed languages are created to satisfy the artistic taste of the author.\"\"\"\n",
    "\n",
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')\n",
    "\n",
    "\n",
    "token_integers = tokenizer.encode(input_text)\n",
    "\n",
    "# setting chunksize with max token limit as 800, because bart accepts the maximum of 1024 tokens. At each step, it add the summary\n",
    "# from previous chunk, which contains maximum of 100 tokens. The return summary will contain a maximum of 100 tokens. (800+100+100\n",
    "# = 1000 tokens). It requires some token for internal processing. so, 800 would be a good chunk size.\n",
    "chunksize = 800\n",
    "chunks = [\n",
    "    token_integers[i : i + chunksize]\n",
    "    for i in range(0, len(token_integers), chunksize)\n",
    "]\n",
    "\n",
    "chunks = [tokenizer.decode(chunk) for chunk in chunks]\n",
    "\n",
    "prev_summary = \"\"\n",
    "total_tokens_used = 0\n",
    "tokens_used = 0\n",
    "responses = []\n",
    "\n",
    "for chunk in chunks:\n",
    "    # Combine previous summary and current chunk for summarization\n",
    "    summary_chunk = 'Provide a summary of the given debate within a limit of 100 words:'+ prev_summary + chunk  \n",
    "\n",
    "    print('----------------------')\n",
    "    print('summary_chunk',summary_chunk)\n",
    "\n",
    "    response = summarizer(summary_chunk, max_length=100, min_length=80)\n",
    "\n",
    "    summary = response[0]['summary_text']\n",
    "    \n",
    "    # Update previous summary for the next iteration\n",
    "    prev_summary = summary  \n",
    "\n",
    "    responses.append(summary)\n",
    "\n",
    "print('**************')\n",
    "print(responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c049b785-c60f-44d4-91f7-5840f7e23e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# function to porcess dfs input and create bart summaries\n",
    "def create_bart_summaries(input_folder, output_folder, max_tokens):\n",
    "\n",
    "    # Iterate through files in the input folder\n",
    "    for filename in os.listdir(input_folder):\n",
    "        chunks = []\n",
    "        if filename.endswith(\".txt\"):\n",
    "            print(filename)\n",
    "            input_file_path = os.path.join(input_folder, filename)\n",
    "            \n",
    "            # read the content of the file\n",
    "            with open(input_file_path, 'r', encoding='utf-8') as file:\n",
    "                file_content = file.read()\n",
    "\n",
    "            tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')\n",
    "\n",
    "\n",
    "            token_integers = tokenizer.encode(file_content)\n",
    "            \n",
    "            chunksize = max_tokens\n",
    "            chunks = [\n",
    "                token_integers[i : i + chunksize]\n",
    "                for i in range(0, len(token_integers), chunksize)\n",
    "            ]\n",
    "            \n",
    "            chunks = [tokenizer.decode(chunk) for chunk in chunks]\n",
    "            \n",
    "            prev_summary = \"\"\n",
    "            total_tokens_used = 0\n",
    "            tokens_used = 0\n",
    "            responses = []\n",
    "            \n",
    "            for chunk in chunks:\n",
    "                # Combine previous summary and current chunk for summarization\n",
    "                summary_chunk = 'Provide a summary of the given debate within a limit of 150 words:'+ prev_summary + chunk  \n",
    "            \n",
    "                response = summarizer(summary_chunk, max_length=100, min_length=80)\n",
    "            \n",
    "                summary = response[0]['summary_text']\n",
    "                \n",
    "                # Update previous summary for the next iteration\n",
    "                prev_summary = summary  \n",
    "            \n",
    "                responses.append(summary)\n",
    "\n",
    "            # write the concatenated result to a text file in the output folder\n",
    "            output_file_path = os.path.join(output_folder, filename)\n",
    "            with open(output_file_path, 'w', encoding=\"utf8\") as output_file:\n",
    "                output_file.write(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "feb78315-688b-4760-a627-c03791b39154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3d-printer-and-guns-should-blueprints-of-3d-printed-weapons-be-prohibited-17593.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1041 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a-bar-of-soap-is-better-than-a-bottle-of-shower-gel-21205.txt\n",
      "a-childs-primary-carer-should-receive-a-wage-until-the-child-enters-primary-school-or-some-other-form-of-care-17763.txt\n",
      "a-flat-asset-tax-is-all-the-tax-we-should-ever-pay-16974.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 150, but your input_length is only 147. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=73)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a-free-press-is-necessary-to-democracy-8559.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 150, but your input_length is only 147. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=73)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a-permanent-venue-for-the-olympic-games-1335.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2880 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "addressing-psychosocial-factors-is-essential-to-reducing-or-preventing-school-shootings-11784.txt\n",
      "affirmative-action-useful-once-outdated-today-1715.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (21788 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agile-certifications-do-not-advance-agile-thinking-14073.txt\n",
      "air-traffic-control-atc-should-not-be-privatized-12138.txt\n",
      "alex-jones-has-a-negative-impact-on-society-19233.txt\n",
      "all-cars-should-be-run-at-high-revs-sometimes-to-prevent-carbon-build-up-9119.txt\n",
      "all-children-should-be-taught-to-code-in-school-6844.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3058 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all-dating-sites-should-include-background-checks-17733.txt\n",
      "all-drugs-should-be-legalized-7100.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (14358 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all-human-interaction-should-be-voluntary-6835.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1823 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all-humans-should-be-vegan-2762.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (61190 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all-transgender-athletes-should-have-to-compete-in-mens-divisions-21194.txt\n",
      "all-us-and-eu-sanctions-imposed-on-russia-since-2014-should-be-lifted-25506.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (7120 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "american-civil-war-1861-65-was-mainly-about-slavery-19208.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1056 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "american-football-should-be-banned-10143.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (5855 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anarchy-is-the-only-ethical-system-of-society-6144.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (7653 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "are-all-our-actions-selfish-to-some-degree-31063.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1672 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "are-bitcoin-and-anonymous-payments-beneficial-for-the-world-984.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (16650 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "are-bitcoin-and-similar-cryptocurrencies-good-for-the-world-333.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (7317 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "are-canadas-new-impaired-driving-laws-appropriate-18375.txt\n",
      "are-cats-more-preferred-by-humans-than-dogs-31829.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1309 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "are-constructed-languages-useful-and-do-we-need-more-of-them-16548.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1169 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "are-countries-right-to-dispel-russian-diplomats-over-the-skripal-poisoning-case-12134.txt\n",
      "are-crop-circles-created-by-extraterrestials-19554.txt\n",
      "are-cryptocurrencies-and-blockchain-technologies-the-next-industrial-revolution-2976.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (6148 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "are-decentralized-marketplaces-like-open-bazaar-antithetical-to-privacy-preserving-trustless-marketplaces-18191.txt\n",
      "are-exorbitant-transfer-fees-in-football-soccer-unethical-5096.txt\n",
      "are-free-markets-better-for-humans-than-regulated-markets-7841.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2991 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "are-gender-and-sex-the-same-thing-30703.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1688 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "are-ghosts-real-23956.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1257 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "are-gmos-the-solution-to-limited-means-14152.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2387 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "are-homeopathic-remedies-fraudulent-8668.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1063 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "are-humans-evil-9827.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2600 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "are-humans-fundamentally-different-from-other-animals-9265.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3980 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "are-humans-primarily-driven-by-emotions-rather-than-rationality-14191.txt\n",
      "are-identity-politics-detrimental-to-society-7018.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (10797 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "are-k-12-teachers-already-paid-enough-in-america-21844.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2113 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "are-killer-drones-an-acceptable-weapon-in-war-17822.txt\n",
      "are-laptops-or-tablets-better-for-college-students-18642.txt\n",
      "are-men-the-biggest-problem-mankind-faces-13628.txt\n",
      "are-modern-democracies-destined-to-fail-due-to-their-inherent-weaknesses-26330.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (8031 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Your max_length is set to 150, but your input_length is only 137. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=68)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "are-people-who-do-immoral-things-immoral-9202.txt\n",
      "are-problems-in-developing-countries-worse-than-developed-ones-15573.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2131 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "are-public-speakers-that-promote-self-help-making-a-difference-or-just-enriching-themselves-22957.txt\n",
      "are-purity-pledges-harmful-29355.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (7411 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "are-real-estate-brokers-really-necessary-7185.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1957 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "are-the-milankovitch-cycles-major-causes-of-climate-change-14194.txt\n",
      "are-the-rules-of-the-criminal-justice-system-fair-15002.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2155 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "are-there-any-working-business-models-for-journalism-10310.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2130 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "are-unions-a-good-thing-2760.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1510 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "are-we-morally-compelled-to-help-others-in-need-18090.txt\n",
      "are-women-better-than-men-26866.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1984 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aritificial-intelligence-ai-limiting-an-ais-freedom-of-thought-is-unethical-15943.txt\n",
      "arranged-marriages-are-better-than-love-matches-16340.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (8736 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "# input and output folder paths\n",
    "# input - dfs input\n",
    "# output - bart summaries\n",
    "# Replace the below with desired input and output path\n",
    "input_folder_path = 'C:/Users/Nila/Documents/Main Scripts_25.12.2023/Jupyter Notebooks/complete testing/llm_input/dfs_linearized/'\n",
    "output_folder_path = 'C:/Users/Nila/Documents/Main Scripts_25.12.2023/Jupyter Notebooks/complete testing/llm_output/BART-CNN/depth_first/'\n",
    "\n",
    "#input_folder_path = 'C:/Users/Nila/Documents/Project/benchmark/data/kialo-nilesc/sample-test/input/'\n",
    "#output_folder_path = 'C:/Users/Nila/Documents/Project/benchmark/data/kialo-nilesc/sample-test/output/'\n",
    "\n",
    "create_bart_summaries(input_folder_path, output_folder_path, 800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0217ce-08de-421f-9a65-b7b125a6833c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
